{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the cv2 module\n",
    "import cv2\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.models import Sequential \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  5216 and the image is of the shape (200)\n"
     ]
    }
   ],
   "source": [
    "# download the data into two instances, training data and testing data\n",
    "\n",
    "train_path = 'C:/Users/Kirsten Korsrud/Documents/diabetes data/chest_xray/train'\n",
    "test_path = 'C:/Users/Kirsten Korsrud/Documents/diabetes data/chest_xray/test'\n",
    "\n",
    "# create lists to store the data in once split into the images (X) and classification (y)\n",
    "x_test = []\n",
    "X_train = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "for folder in os.listdir(train_path):\n",
    "\n",
    "    sub_path=train_path+\"/\"+folder\n",
    "\n",
    "    for img in os.listdir(sub_path):\n",
    "\n",
    "        image_path=sub_path+\"/\"+img\n",
    "\n",
    "        img_arr=cv2.imread(image_path)\n",
    "    \n",
    "        img_arr=cv2.resize(img_arr,(200,200))\n",
    "        \n",
    "        # store the image data into X_train list\n",
    "        X_train.append(img_arr)\n",
    "        \n",
    "        # If the image corresponds to a 'normal' lung classification, store 0 into y_train\n",
    "        if img == 'NORMAL':\n",
    "            y_train.append(0)\n",
    "        else:\n",
    "         # If the image corresponds to a 'pneumonia' lung classification, store 1 into y_train\n",
    "            y_train.append(1)\n",
    "                \n",
    "        \n",
    "for folder in os.listdir(test_path):\n",
    "\n",
    "    sub_path=test_path+\"/\"+folder\n",
    "\n",
    "    for img in os.listdir(sub_path):\n",
    "\n",
    "        image_path=sub_path+\"/\"+img\n",
    "\n",
    "        img_arr=cv2.imread(image_path)\n",
    "\n",
    "        img_arr=cv2.resize(img_arr,(200,200))\n",
    "\n",
    "        # store the image data into X_test list\n",
    "        x_test.append(img_arr)\n",
    "        \n",
    "        # If the image corresponds to a 'normal' lung classification, store 0 into y_test\n",
    "        if img == 'NORMAL':\n",
    "            y_test.append(0)\n",
    "        else:\n",
    "        # If the image corresponds to a 'pneumonia' lung classification, store 1 into y_test\n",
    "            y_test.append(1)\n",
    "        \n",
    "X_train = np.array(X_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(\"Number of training examples: \", X_train.shape[0],\n",
    "     \"and the image is of the shape (%d)\"%(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to smaller float types \n",
    "X_train = X_train.astype(\"float32\")/255\n",
    "x_test = x_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216, 2)\n",
      "(624, 2)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "input_shape = (200,200,3)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "print(y_train.shape)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 99, 99, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 48, 48, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 147456)            0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 147456)            0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 294914    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 314,306\n",
      "Trainable params: 314,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train the model \n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37/37 [==============================] - 73s 2s/step - loss: 0.0186 - accuracy: 0.9872 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 71s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 72s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 72s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 72s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 73s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 72s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 72s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 71s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 72s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b809a69f40>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_c = np.argmax(y_pred, axis=1)\n",
    "y_test_c = np.argmax(y_test, axis=1)\n",
    "matrix_confusion = confusion_matrix(y_test_c, y_pred_c)\n",
    "\n",
    "sns.heatmap(matrix_confusion, square=True, annot=True, cmap='Blues', fmt='d', cbar=False )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
